{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Project Part 3\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/entrylevelcs/CS39AA-Project/blob/main/project_part3.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/entrylevelcs/CS39AA-Project/blob/main/project_part3.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction/Background\n","\n","For this part of the project we are using the bert based pretrained model and training it using our two data sets to see how accurate we can get the predictions to be."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Using pretrained models to improve accuracy"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}],"source":["# import all of the python modules/packages you'll need here\n","import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,  TrainingArguments, Trainer\n","from datasets import Dataset, load_metric\n","import os\n","import wandb\n","import random\n","# ..."]},{"cell_type":"markdown","metadata":{},"source":["Set up our wandb information to track our project."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\"\"\"\n","wandb.login()\n","os.environ[\"WANDB_DISABLED\"] = \"false\"\n","os.environ[\"WANDB_LOG_MODEL\"] = \"true\"\n","os.environ[\"WANDB_PROJECT\"] = \"real_data\"\n","os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"project_part3.ipynb\"\n","\"\"\"\n","#Uncomment the above for tracking\n","#remove line below for tracking\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set from real steam reviews. The specific set of data that I am using for this notebook comes from https://www.kaggle.com/datasets/andrewmvd/steam-reviews/ but is just a sample of 25000 from the entire set."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["human_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/human_dataset.csv'\n","df = pd.read_csv(human_data)\n","df = df[df[\"review_text\"].notnull()]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set that was generated by chatgpt. This review data started as only being about CS:GO but has been expanded to be more general and talk about other games."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["ai_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/gpt3.5_generated_data.csv'\n","df2 = pd.read_csv(ai_data)"]},{"cell_type":"markdown","metadata":{},"source":["We need to reformat the data into forms that are usable to the model. One thing we need to do is reclassify our labels since the model marks \"-1\" as a wrong label. In order to do this we replace the \"recommended\" labels, 1, with 1 and the \"not recommended\" labels, -1, with 0."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df = df.rename(columns={\"review_text\": \"text\", \"review_score\": \"label\"})\n","df2 = df2.rename(columns={\"Review\": \"text\", \" Sentiment\": \"label\"})\n","class_tok2idx = dict({1: 1, -1: 0})\n","df['label'] = df['label'].apply(lambda x: class_tok2idx[x])\n","df2['label'] = df2['label'].apply(lambda x: class_tok2idx[x])"]},{"cell_type":"markdown","metadata":{},"source":["We get some numbers related to the two data sets sizes so that the data going into both training models are the same."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["ai_data_size = len(df2)\n","sample_size = len(df)\n","proportion = 1 - ((sample_size-ai_data_size)/sample_size)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize our tokenizer and models."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if _pandas_api.is_sparse(col):\n","c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 28997. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 28997. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"]},{"data":{"text/plain":["Embedding(28997, 768)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["real_data_raw = Dataset.from_pandas(df[['label', 'text']])\n","simulated_data_raw = Dataset.from_pandas(df2)\n","MODEL_NAME = 'bert-base-cased'\n","MAX_LENGTH = 55\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.add_special_tokens({'pad_token': '<pad>'})\n","realModel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, max_length=MAX_LENGTH, output_attentions=False, output_hidden_states=False)\n","simulatedModel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, max_length=MAX_LENGTH, output_attentions=False, output_hidden_states=False)\n","realModel.resize_token_embeddings(len(tokenizer))\n","simulatedModel.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"markdown","metadata":{},"source":["Tokenize our data sets so that they can be used in the models."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0aff29ee66ce47399b004e632dcecf43","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/24971 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1e9d697d2a14ad6a3962de91659bcd8","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2496 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=MAX_LENGTH)\n","\n","real_data = real_data_raw.map(tokenize_function, batched=True)\n","simulated_data = simulated_data_raw.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{},"source":["Data set that is sampled from the full set so that we can use our models to predict it."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if _pandas_api.is_sparse(col):\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6ba98e5eff894eaaae070ff538a4ee16","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/12500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["pdata = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/extra.csv'\n","df3 = pd.read_csv(pdata)\n","df3 = df3[df3[\"review_text\"].notnull()]\n","df3 = df3.rename(columns={\"review_text\": \"text\", \"review_score\": \"label\"})\n","df3['label'] = df3['label'].apply(lambda x: class_tok2idx[x])\n","predict_data_raw = Dataset.from_pandas(df3[['label', 'text']])\n","predict_data = predict_data_raw.map(tokenize_function, batched=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["Split the real data into the training data and the evaluation data set. Both the simulated and real training data sets will use the real_data_eval data set as the evaluation data sets. With this split both our simulated training data set and our real training data set are the same size."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_prop = proportion\n","real_data_train = real_data.select(range(int(len(real_data)*train_prop)))\n","real_data_eval = real_data.select(range(int(len(real_data)*train_prop), len(real_data)))"]},{"cell_type":"markdown","metadata":{},"source":["Set up our real model that is trained on the real data. Also initialize our different hyperparameters that we need to cycle through in order to find the optimal combination. I was unable to get the wandb sweep to work so instead I just reran the notebook eight times in order to \"optimize\" the hyper parameters. Best values found for the real model were batchSize = 32, learningRate = 1e-4 and weight_decay = 0."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["\"\"\"\n","batchSize = [8, 32, 64, 128, 256]\n","learningRate = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n","weightDecay = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n","batchSize = batchSize[random.randint(0,4)]\n","learningRate = learningRate[random.randint(0,4)]\n","weightDecay = weightDecay[random.randint(0,6)]\n","\"\"\"\n","# uncomment above to get random hyperparameter values\n","batchSize = 32\n","learningRate = 1e-4\n","weightDecay = 0.0\n","\n","def compute_metrics(eval_pred):\n","    metrics = dict()\n","\n","    accuracy_metric = load_metric('accuracy')\n","    precision_metric = load_metric('precision')\n","    recall_metric = load_metric('recall')\n","    f1_metric = load_metric('f1')\n","\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=-1)\n","    \n","    metrics.update(accuracy_metric.compute(predictions=preds, references=labels))\n","    metrics.update(precision_metric.compute(predictions=preds, references=labels, average='weighted'))\n","    metrics.update(recall_metric.compute(predictions=preds, references=labels, average='weighted'))\n","    metrics.update(f1_metric.compute(predictions=preds, references=labels, average='weighted'))\n","    \n","    return metrics\n","\n","real_training_args = TrainingArguments(num_train_epochs=3,\n","                                  do_train=True,\n","                                  report_to=None, #wandb #for tracking\n","                                  output_dir=\"real\",\n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=78,\n","                                  learning_rate=learningRate,\n","                                  weight_decay=weightDecay,\n","                                  per_device_train_batch_size=batchSize,\n","                                  per_device_eval_batch_size=32)\n","\n","real_trainer = Trainer(model = realModel, \n","                  args = real_training_args,\n","                  train_dataset = real_data_train, \n","                  eval_dataset = real_data_eval,\n","                  compute_metrics = compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Print out the different hyperparameters so I can log them."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["32\n","0.0001\n","0.0\n"]}],"source":["print(batchSize)\n","print(learningRate)\n","print(weightDecay)"]},{"cell_type":"markdown","metadata":{},"source":["Set up our simulated model that is trained on simulated data. Best values found are included in the code block below."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["batchSize = 32\n","learningRate = 1e-5\n","weightDecay = 0.1\n","\n","sim_training_args = TrainingArguments(num_train_epochs=3,\n","                                  do_train=True,\n","                                  report_to=None,\n","                                  output_dir=\"simulated\",\n","                                  evaluation_strategy=\"epoch\",\n","                                  eval_steps=78,\n","                                  learning_rate=learningRate,\n","                                  weight_decay=weightDecay,\n","                                  per_device_train_batch_size=batchSize,\n","                                  per_device_eval_batch_size=32)\n","\n","sim_trainer = Trainer(model = simulatedModel, \n","                  args = sim_training_args,\n","                  train_dataset = simulated_data, \n","                  eval_dataset = real_data_eval,\n","                  compute_metrics = compute_metrics,\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU\n"]}],"source":["if torch.cuda.is_available():\n","    device = \"cuda:0\"\n","    print(\"Using GPU\")\n","else: \n","    device = \"cpu\"\n"]},{"cell_type":"markdown","metadata":{},"source":["Train our real data model."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17a678e144eb40b58f00b8201635cc1c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/234 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18a5bd1c788941a8996a768d36243b08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Muajeh Lee\\AppData\\Local\\Temp\\ipykernel_12516\\2017950199.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  accuracy_metric = load_metric('accuracy')\n"]},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.36119842529296875, 'eval_accuracy': 0.8494838939313045, 'eval_precision': 0.8335323612613328, 'eval_recall': 0.8494838939313045, 'eval_f1': 0.8221807845141444, 'eval_runtime': 52.1292, 'eval_samples_per_second': 431.16, 'eval_steps_per_second': 13.486, 'epoch': 1.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08aad77353fb4d07804c4fed059250ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.368147075176239, 'eval_accuracy': 0.8558907278875245, 'eval_precision': 0.8419890690399171, 'eval_recall': 0.8558907278875245, 'eval_f1': 0.8438892166379125, 'eval_runtime': 50.9698, 'eval_samples_per_second': 440.967, 'eval_steps_per_second': 13.792, 'epoch': 2.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4245f9274934cf8bf99ead01ade511b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.48628753423690796, 'eval_accuracy': 0.8546004627157857, 'eval_precision': 0.8417203637280933, 'eval_recall': 0.8546004627157857, 'eval_f1': 0.8446118211622624, 'eval_runtime': 51.4348, 'eval_samples_per_second': 436.981, 'eval_steps_per_second': 13.668, 'epoch': 3.0}\n","{'train_runtime': 208.185, 'train_samples_per_second': 35.954, 'train_steps_per_second': 1.124, 'train_loss': 0.28023388854458803, 'epoch': 3.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e20a766bd9a4b3a80d33565d4eeac9c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.48628753423690796,\n"," 'eval_accuracy': 0.8546004627157857,\n"," 'eval_precision': 0.8417203637280933,\n"," 'eval_recall': 0.8546004627157857,\n"," 'eval_f1': 0.8446118211622624,\n"," 'eval_runtime': 51.1386,\n"," 'eval_samples_per_second': 439.511,\n"," 'eval_steps_per_second': 13.747,\n"," 'epoch': 3.0}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["realModel.to(device)\n","torch.set_grad_enabled(True)\n","real_trainer.train()\n","real_trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["Train our simulated data model."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1677bd2930d846a9a2505a1a8be94d19","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/234 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33b866309a2b4f6383d326deb39daf56","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.507163941860199, 'eval_accuracy': 0.7797650827549386, 'eval_precision': 0.8049571808803667, 'eval_recall': 0.7797650827549386, 'eval_f1': 0.7901366219028239, 'eval_runtime': 51.1279, 'eval_samples_per_second': 439.604, 'eval_steps_per_second': 13.75, 'epoch': 1.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d627f9bbe68c4abd8ada00d3f617b8af","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.7969406843185425, 'eval_accuracy': 0.7334935041822388, 'eval_precision': 0.8066929532056002, 'eval_recall': 0.7334935041822388, 'eval_f1': 0.757704095772947, 'eval_runtime': 50.998, 'eval_samples_per_second': 440.723, 'eval_steps_per_second': 13.785, 'epoch': 2.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fbf19aa86ca2485d8ee2d2c87f03c4e4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.9118539094924927, 'eval_accuracy': 0.7158302189001602, 'eval_precision': 0.8046701901215098, 'eval_recall': 0.7158302189001602, 'eval_f1': 0.7438469931408687, 'eval_runtime': 52.3374, 'eval_samples_per_second': 429.444, 'eval_steps_per_second': 13.432, 'epoch': 3.0}\n","{'train_runtime': 207.1823, 'train_samples_per_second': 36.142, 'train_steps_per_second': 1.129, 'train_loss': 0.15104535094693175, 'epoch': 3.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eac04209d34847e3802eb0959213b724","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/703 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.9118539094924927,\n"," 'eval_accuracy': 0.7158302189001602,\n"," 'eval_precision': 0.8046701901215098,\n"," 'eval_recall': 0.7158302189001602,\n"," 'eval_f1': 0.7438469931408687,\n"," 'eval_runtime': 51.4571,\n"," 'eval_samples_per_second': 436.791,\n"," 'eval_steps_per_second': 13.662,\n"," 'epoch': 3.0}"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["simulatedModel.to(device)\n","sim_trainer.train()\n","sim_trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["Use the real model with the optimal parameters to predict the extra data."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"216a54df2a764a98ab64263254b35798","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[-0.65022147,  0.78339416],\n","       [-2.6378212 ,  3.0397048 ],\n","       [-1.5313379 ,  1.2616408 ],\n","       ...,\n","       [-3.0483782 ,  3.4318466 ],\n","       [-0.65022135,  0.78339404],\n","       [-2.6929402 ,  3.0046084 ]], dtype=float32), label_ids=array([0, 1, 0, ..., 1, 0, 1], dtype=int64), metrics={'test_loss': 0.4689282178878784, 'test_accuracy': 0.85944, 'test_precision': 0.8469438366844293, 'test_recall': 0.85944, 'test_f1': 0.8496350014566572, 'test_runtime': 30.63, 'test_samples_per_second': 408.096, 'test_steps_per_second': 12.765})"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["real_trainer.predict(predict_data)"]},{"cell_type":"markdown","metadata":{},"source":["Use our simulated model with the optimal parameters to predict the extra data."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c44a70d2acf45be9aa7d0730bd4f4e8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/391 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["PredictionOutput(predictions=array([[-1.9441288,  0.7717161],\n","       [-3.2725382,  2.6734142],\n","       [ 1.6970272, -1.7514855],\n","       ...,\n","       [-1.7533967,  1.0316035],\n","       [-1.9441302,  0.7717168],\n","       [ 2.0968409, -1.9795   ]], dtype=float32), label_ids=array([0, 1, 0, ..., 1, 0, 1], dtype=int64), metrics={'test_loss': 0.9185799956321716, 'test_accuracy': 0.70984, 'test_precision': 0.8035024448038779, 'test_recall': 0.70984, 'test_f1': 0.7395756388256645, 'test_runtime': 31.5503, 'test_samples_per_second': 396.193, 'test_steps_per_second': 12.393})"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["sim_trainer.predict(predict_data)"]},{"cell_type":"markdown","metadata":{},"source":["For the full list of random hyperparameter trials check the hyper_variants.txt in this github repository."]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
