{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Project Part 2\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/entrylevelcs/CS39AA-Project/blob/main/project_part2.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/entrylevelcs/CS39AA-Project/blob/main/project_part2.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction/Background\n","\n","For this part of the project we are taking the nearest neighbors model and training it using both our AI and real data sets. From this simple model we can see how well each of the different training data sets do after being optimizing the hyperparameters of this simple model."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Simple Modeling with KNeighborsClassifier"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# import all of the python modules/packages you'll need here\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","# ..."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set from real steam reviews. The specific set of data that I am using for this notebook comes from https://www.kaggle.com/datasets/andrewmvd/steam-reviews/ but is just a sample of 25000 from the entire set."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["human_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/human_dataset.csv'\n","df = pd.read_csv(human_data)\n","df = df[df[\"review_text\"].notnull()]\n","sample_size = len(df)\n","#sample_size = 25000\n","#df = df.sample(sample_size)\n","# previous two lines are for sampling from the entire human dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>app_id</th>\n","      <th>app_name</th>\n","      <th>review_text</th>\n","      <th>review_score</th>\n","      <th>review_votes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>949219</td>\n","      <td>212680</td>\n","      <td>FTL: Faster Than Light</td>\n","      <td>Really gg.</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1151136</td>\n","      <td>218620</td>\n","      <td>PAYDAY 2</td>\n","      <td>I'm not entirely sure what I was expecting, bu...</td>\n","      <td>-1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4031479</td>\n","      <td>31280</td>\n","      <td>Poker Night at the Inventory</td>\n","      <td>First I thought I was gonna buy this, play so ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6382952</td>\n","      <td>94400</td>\n","      <td>Nidhogg</td>\n","      <td>Stab your opponent repeatedly and win the glor...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3770644</td>\n","      <td>300060</td>\n","      <td>ADR1FT</td>\n","      <td>I think this experience is pretty much defined...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  app_id                      app_name  \\\n","0      949219  212680        FTL: Faster Than Light   \n","1     1151136  218620                      PAYDAY 2   \n","2     4031479   31280  Poker Night at the Inventory   \n","3     6382952   94400                       Nidhogg   \n","4     3770644  300060                        ADR1FT   \n","\n","                                         review_text  review_score  \\\n","0                                         Really gg.             1   \n","1  I'm not entirely sure what I was expecting, bu...            -1   \n","2  First I thought I was gonna buy this, play so ...             1   \n","3  Stab your opponent repeatedly and win the glor...             1   \n","4  I think this experience is pretty much defined...             1   \n","\n","   review_votes  \n","0             0  \n","1             0  \n","2             0  \n","3             0  \n","4             0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set that was generated by chatgpt. This review data started as only being about CS:GO but has been expanded to be more general and talk about other games."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["ai_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/gpt3.5_generated_data.csv'\n","df2 = pd.read_csv(ai_data)"]},{"cell_type":"markdown","metadata":{},"source":["Sets up our different inputs and outputs. X and y are the inputs and outputs from the real steam reviews while X1 and y1 are from the AI generated reviews. I also adjusted the test size so that the training data size the same length as the AI generated data set. From the shape of each we can see that the vocab size is 11127 words."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["X = df['review_text'].copy()\n","y = df['review_score'].copy()\n","X1 = df2['Review'].copy()\n","y1 = df2[' Sentiment'].copy()\n","ai_data_size = X1.size\n","\n","X_train_raw, X_val_raw, y_train, y_val = train_test_split(X, y, test_size=((sample_size-ai_data_size)/sample_size), random_state=21)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["real_data = X_train_raw.copy()\n","real_data['scores'] = y_train.copy()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, GPT2ForTokenClassification,  TrainingArguments, Trainer\n","from datasets import Dataset, load_metric\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n","realModel = GPT2ForTokenClassification.from_pretrained(\"gpt2\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"C:\\Users\\Muajeh Lee\\AppData\\Local\\Temp\\ipykernel_2196\\2853803468.py\", line 1, in <module>\n","    df_raw = Dataset.from_pandas(real_data)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py\", line 846, in from_pandas\n","    table = InMemoryTable.from_pandas(\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\datasets\\table.py\", line 747, in from_pandas\n","    return cls(pa.Table.from_pandas(*args, **kwargs))\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"pyarrow\\table.pxi\", line 3557, in pyarrow.lib.Table.from_pandas\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py\", line 570, in dataframe_to_arrays\n","    convert_fields) = _get_columns_to_convert(df, schema, preserve_index,\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py\", line 349, in _get_columns_to_convert\n","    columns = _resolve_columns_of_interest(df, schema, columns)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py\", line 523, in _resolve_columns_of_interest\n","    columns = df.columns\n","              ^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6204, in __getattr__\n","    return object.__getattribute__(self, name)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","AttributeError: 'Series' object has no attribute 'columns'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n","    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n","    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1155, in get_records\n","    FrameInfo(\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 780, in __init__\n","    ix = inspect.getsourcelines(frame)\n","         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\inspect.py\", line 1244, in getsourcelines\n","    lines, lnum = findsource(object)\n","                  ^^^^^^^^^^^^^^^^^^\n","  File \"c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\inspect.py\", line 1073, in findsource\n","    raise OSError('source code not available')\n","OSError: source code not available\n"]}],"source":["df_raw = Dataset.from_pandas(real_data)\n","\n","def tokenize_function(examples):\n","    return tokenizer(examples['review_text'], truncation=True, max_length=50)\n","\n","df = df_raw.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'ds_train' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mm:\\Documents\\NLP\\project\\CS39AA-Project\\project_part3.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m metric\u001b[39m.\u001b[39mcompute(predictions\u001b[39m=\u001b[39mpredictions, references\u001b[39m=\u001b[39mlabels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(num_train_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                   do_train\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                   report_to\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                   per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                   per_device_eval_batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model \u001b[39m=\u001b[39m realModel, \n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                   args \u001b[39m=\u001b[39m training_args,\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                   train_dataset \u001b[39m=\u001b[39m ds_train, \n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                   eval_dataset \u001b[39m=\u001b[39m ds_eval,\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                   compute_metrics \u001b[39m=\u001b[39m compute_metrics,\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/Documents/NLP/project/CS39AA-Project/project_part3.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n","\u001b[1;31mNameError\u001b[0m: name 'ds_train' is not defined"]}],"source":["metric = load_metric(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","training_args = TrainingArguments(num_train_epochs=10,\n","                                  do_train=True,\n","                                  report_to=None,\n","                                  output_dir=\"realData\",\n","                                  evaluation_strategy=\"steps\",\n","                                  eval_steps=200,\n","                                  learning_rate=1e-5,\n","                                  per_device_train_batch_size=32,\n","                                  per_device_eval_batch_size=32)\n","\n","trainer = Trainer(model = realModel, \n","                  args = training_args,\n","                  train_dataset = ds_train, \n","                  eval_dataset = ds_eval,\n","                  compute_metrics = compute_metrics,\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
