{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Project Part 3\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/entrylevelcs/CS39AA-Project/blob/main/project_part3.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/entrylevelcs/CS39AA-Project/blob/main/project_part3.ipynb)\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction/Background\n","\n","For this part of the project we are using the bert based pretrained model and training it using our two data sets to see how accurate we can get the predictions to be."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Using pretrained models to improve accuracy"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n"]}],"source":["# import all of the python modules/packages you'll need here\n","import pandas as pd\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification,  TrainingArguments, Trainer\n","from datasets import Dataset, load_metric\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","# ..."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set from real steam reviews. The specific set of data that I am using for this notebook comes from https://www.kaggle.com/datasets/andrewmvd/steam-reviews/ but is just a sample of 25000 from the entire set."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["human_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/human_dataset.csv'\n","df = pd.read_csv(human_data)\n","df = df[df[\"review_text\"].notnull()]\n","sample_size = len(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get the data set that was generated by chatgpt. This review data started as only being about CS:GO but has been expanded to be more general and talk about other games."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["ai_data = 'https://raw.githubusercontent.com/entrylevelcs/CS39AA-Project/main/gpt3.5_generated_data.csv'\n","df2 = pd.read_csv(ai_data)"]},{"cell_type":"markdown","metadata":{},"source":["We need to reformat the data into forms that are usable to the model. One thing we need to do is reclassify our labels since the model marks \"-1\" as a wrong label. In order to do this we replace the recommended labels, 1, with 0 and the not recommende labels, -1 with 1."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df = df.rename(columns={\"review_text\": \"text\", \"review_score\": \"label\"})\n","df2 = df2.rename(columns={\"Review\": \"text\", \" Sentiment\": \"label\"})\n","classes = df.label.unique().tolist()\n","class_tok2idx = dict((v, k) for k, v in enumerate(classes))\n","df['label'] = df['label'].apply(lambda x: class_tok2idx[x])\n","classes = df2.label.unique().tolist()\n","class_tok2idx = dict((v, k) for k, v in enumerate(classes))\n","df2['label'] = df2['label'].apply(lambda x: class_tok2idx[x])"]},{"cell_type":"markdown","metadata":{},"source":["We get some numbers related to the two data sets sizes so that the data going into both training models are the same."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["ai_data_size = df2.size\n","sample_size = df.size\n","proportion = 1 - ((sample_size-ai_data_size)/sample_size)"]},{"cell_type":"markdown","metadata":{},"source":["Initialize our tokenizer and models."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n","  if _pandas_api.is_sparse(col):\n","c:\\Users\\Muajeh Lee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n","  torch.utils._pytree._register_pytree_node(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 28997. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 28997. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"]},{"data":{"text/plain":["Embedding(28997, 768)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["real_data_raw = Dataset.from_pandas(df[['label', 'text']])\n","simulated_data_raw = Dataset.from_pandas(df2)\n","MODEL_NAME = 'bert-base-cased'\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.add_special_tokens({'pad_token': '<pad>'})\n","realModel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, max_length=55, output_attentions=False, output_hidden_states=False)\n","simulatedModel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2, max_length=55, output_attentions=False, output_hidden_states=False)\n","realModel.resize_token_embeddings(len(tokenizer))\n","simulatedModel.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"markdown","metadata":{},"source":["Tokenize our data sets so that they can be used in the models."]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57d0ede1023f48d0802ca493ad2abd48","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/24971 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bdbe6e0502443408f7ae4b409d11b42","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2496 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding='max_length', truncation=True, max_length=55)\n","\n","real_data = real_data_raw.map(tokenize_function, batched=True)\n","simulated_data = simulated_data_raw.map(tokenize_function, batched=True)"]},{"cell_type":"markdown","metadata":{},"source":["Split the real data into the training data and the evaluation data set. Both the simulated and real training data sets will use the real_data_eval data set as the evaluation data sets. With this split both our simulated training data set and our real training data set are the same size."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_prop = proportion\n","real_data_train = real_data.select(range(int(len(real_data)*train_prop)))\n","real_data_eval = real_data.select(range(int(len(real_data)*train_prop), len(real_data)))"]},{"cell_type":"markdown","metadata":{},"source":["Set up our real model that is trained on the real data."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Muajeh Lee\\AppData\\Local\\Temp\\ipykernel_4880\\3854264034.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n","Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["metric = load_metric(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","real_training_args = TrainingArguments(num_train_epochs=5,\n","                                  do_train=True,\n","                                  report_to=None,\n","                                  output_dir=\"real\",\n","                                  evaluation_strategy=\"steps\",\n","                                  eval_steps=50,\n","                                  learning_rate=1e-5,\n","                                  per_device_train_batch_size=32,\n","                                  per_device_eval_batch_size=32)\n","\n","real_trainer = Trainer(model = realModel, \n","                  args = real_training_args,\n","                  train_dataset = real_data_train, \n","                  eval_dataset = real_data_eval,\n","                  compute_metrics = compute_metrics,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Set up our simulated model that is trained on simulated data."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"]}],"source":["sim_training_args = TrainingArguments(num_train_epochs=5,\n","                                  do_train=True,\n","                                  report_to=None,\n","                                  output_dir=\"simulated\",\n","                                  evaluation_strategy=\"steps\",\n","                                  eval_steps=50,\n","                                  learning_rate=1e-5,\n","                                  per_device_train_batch_size=32,\n","                                  per_device_eval_batch_size=32)\n","\n","sim_trainer = Trainer(model = simulatedModel, \n","                  args = sim_training_args,\n","                  train_dataset = simulated_data, \n","                  eval_dataset = real_data_eval,\n","                  compute_metrics = compute_metrics,\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU\n"]}],"source":["if torch.cuda.is_available():\n","    device = \"cuda:0\"\n","    print(\"Using GPU\")\n","else: \n","    device = \"cpu\"\n"]},{"cell_type":"markdown","metadata":{},"source":["Train our real data model."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3a24e4e97a646b39923398b001b21b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/130 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d72b3c59e4a1462885123bd75e5126f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.45227646827697754, 'eval_accuracy': 0.8186412593206297, 'eval_runtime': 51.8747, 'eval_samples_per_second': 465.352, 'eval_steps_per_second': 14.554, 'epoch': 1.92}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"86648183af16475a8bac3cc55f90b61f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.40105804800987244, 'eval_accuracy': 0.8186412593206297, 'eval_runtime': 50.3002, 'eval_samples_per_second': 479.918, 'eval_steps_per_second': 15.01, 'epoch': 3.85}\n","{'train_runtime': 130.5541, 'train_samples_per_second': 31.826, 'train_steps_per_second': 0.996, 'train_loss': 0.39706529470590446, 'epoch': 5.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"965f52aa4e0b46f0a4fc9c6d3f362661","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.3831833004951477,\n"," 'eval_accuracy': 0.821913835956918,\n"," 'eval_runtime': 49.712,\n"," 'eval_samples_per_second': 485.597,\n"," 'eval_steps_per_second': 15.187,\n"," 'epoch': 5.0}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["realModel.to(device)\n","torch.set_grad_enabled(True)\n","real_trainer.train()\n","real_trainer.evaluate()"]},{"cell_type":"markdown","metadata":{},"source":["Train our simulated data model."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e34071b962f417384329b1263aa7480","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/390 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2b4fd338e44498881e5901890115b8c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.48819759488105774, 'eval_accuracy': 0.7671085335542668, 'eval_runtime': 50.324, 'eval_samples_per_second': 479.692, 'eval_steps_per_second': 15.003, 'epoch': 0.64}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8130e18b6a846e2b9bbe62239776516","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6519426107406616, 'eval_accuracy': 0.7659486329743165, 'eval_runtime': 47.5334, 'eval_samples_per_second': 507.854, 'eval_steps_per_second': 15.884, 'epoch': 1.28}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58e1f5259521424481ac7b04e1dae68b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.866831362247467, 'eval_accuracy': 0.7333057166528584, 'eval_runtime': 46.8524, 'eval_samples_per_second': 515.235, 'eval_steps_per_second': 16.114, 'epoch': 1.92}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8a5aab004574a61ac6a01acb8f216ee","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.075860857963562, 'eval_accuracy': 0.7065865782932892, 'eval_runtime': 49.7305, 'eval_samples_per_second': 485.417, 'eval_steps_per_second': 15.182, 'epoch': 2.56}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a3252de87ef4d54b93e8fbeb357c424","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.041583776473999, 'eval_accuracy': 0.7241922120961061, 'eval_runtime': 49.7636, 'eval_samples_per_second': 485.093, 'eval_steps_per_second': 15.172, 'epoch': 3.21}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"77baaa6a27374eec99ca19ea01fde2fc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.190108299255371, 'eval_accuracy': 0.6944904722452361, 'eval_runtime': 51.7424, 'eval_samples_per_second': 466.542, 'eval_steps_per_second': 14.592, 'epoch': 3.85}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81d19f6cf600442ab9fe93b421009be7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.1267844438552856, 'eval_accuracy': 0.7207125103562552, 'eval_runtime': 49.8369, 'eval_samples_per_second': 484.38, 'eval_steps_per_second': 15.149, 'epoch': 4.49}\n","{'train_runtime': 428.9347, 'train_samples_per_second': 29.095, 'train_steps_per_second': 0.909, 'train_loss': 0.10714641473232171, 'epoch': 5.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d388609fa3743c1bf14d65d7d63e744","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/755 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 1.214277982711792,\n"," 'eval_accuracy': 0.7009942004971003,\n"," 'eval_runtime': 49.9315,\n"," 'eval_samples_per_second': 483.462,\n"," 'eval_steps_per_second': 15.121,\n"," 'epoch': 5.0}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["simulatedModel.to(device)\n","sim_trainer.train()\n","sim_trainer.evaluate()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb3398f4b21c7b026dd5874af3f954bf25f1e8ff81e25d82a94abcbbaacf760b"}}},"nbformat":4,"nbformat_minor":2}
